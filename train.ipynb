{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30503d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob \n",
    "from ultralytics import YOLO\n",
    "import torch_directml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a6aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DirectML Device detected: privateuseone:0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    device = torch_directml.device()\n",
    "    print(f\"DirectML Device detected: {device}\")\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70313af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Scanning c:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\manual_annotation_workspace for annotated images...\n",
      "Found 198 annotated images.\n",
      "Classes found: ['cracking', 'layer_shifting', 'off_platform', 'stringing']\n",
      "\n",
      ">>> SUCCESS! Dataset ready at: c:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\fdm_manual_dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Florian Caspar\\\\Desktop\\\\Desly\\\\DefectClassification-main\\\\fdm_manual_dataset\\\\data.yaml'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_DIR = os.path.join(os.getcwd(), 'manual_annotation_workspace')\n",
    "DEST_DIR = os.path.join(os.getcwd(), 'fdm_manual_dataset')\n",
    "\n",
    "def organize_dataset():\n",
    "    \n",
    "    images = []\n",
    "    # Scan for common image extensions\n",
    "    for ext in ['*.jpg', '*.png', '*.jpeg']:\n",
    "        # FIXED: Using glob.glob() to avoid the TypeError\n",
    "        images.extend(glob.glob(os.path.join(SOURCE_DIR, ext)))\n",
    "    \n",
    "    annotated_pairs = []\n",
    "    \n",
    "    print(f\">>> Scanning {SOURCE_DIR} for annotated images...\")\n",
    "    \n",
    "    for img_path in images:\n",
    "        base_name = os.path.splitext(img_path)[0]\n",
    "        txt_path = base_name + \".txt\"\n",
    "        \n",
    "        # We only keep images that have a matching .txt label file\n",
    "        if os.path.exists(txt_path):\n",
    "            annotated_pairs.append((img_path, txt_path))\n",
    "        else:\n",
    "\n",
    "            print(f\"Skipping un-annotated image: {os.path.basename(img_path)}\")\n",
    "\n",
    "    if not annotated_pairs:\n",
    "        raise ValueError(\"No annotated (.txt) files found! Did you save them in YOLO format inside the 'manual_annotation_workspace' folder?\")\n",
    "\n",
    "    \n",
    "    classes_file = os.path.join(SOURCE_DIR, 'classes.txt')\n",
    "    if not os.path.exists(classes_file):\n",
    "        raise FileNotFoundError(\"classes.txt not found. LabelImg creates this automatically when you save. Did you define classes?\")\n",
    "    \n",
    "    with open(classes_file, 'r') as f:\n",
    "        class_names = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    print(f\"Found {len(annotated_pairs)} annotated images.\")\n",
    "    print(f\"Classes found: {class_names}\")\n",
    "\n",
    "    \n",
    "    train_pairs, val_pairs = train_test_split(annotated_pairs, test_size=0.1, random_state=42)\n",
    "\n",
    "    \n",
    "    if os.path.exists(DEST_DIR):\n",
    "        try:\n",
    "            shutil.rmtree(DEST_DIR)\n",
    "        except:\n",
    "            pass \n",
    "            \n",
    "    for split, pairs in [('train', train_pairs), ('val', val_pairs)]:\n",
    "        img_dest = os.path.join(DEST_DIR, 'images', split)\n",
    "        lbl_dest = os.path.join(DEST_DIR, 'labels', split)\n",
    "        os.makedirs(img_dest, exist_ok=True)\n",
    "        os.makedirs(lbl_dest, exist_ok=True)\n",
    "        \n",
    "        for img_src, txt_src in pairs:\n",
    "            shutil.copy(img_src, os.path.join(img_dest, os.path.basename(img_src)))\n",
    "            shutil.copy(txt_src, os.path.join(lbl_dest, os.path.basename(txt_src)))\n",
    "\n",
    "    # 5. Create data.yaml\n",
    "    yaml_content = {\n",
    "        'path': DEST_DIR,\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'nc': len(class_names),\n",
    "        'names': {i: name for i, name in enumerate(class_names)}\n",
    "    }\n",
    "    \n",
    "    yaml_path = os.path.join(DEST_DIR, 'data.yaml')\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(yaml_content, f)\n",
    "\n",
    "    print(f\"\\n>>> SUCCESS! Dataset ready at: {DEST_DIR}\")\n",
    "    return yaml_path\n",
    "\n",
    "\n",
    "organize_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4dc04f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: privateuseone:0\n",
      "Training model : yolov8m.pt\n",
      ">>> Starting training using: c:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\fdm_manual_dataset\\data.yaml\n",
      "Ultralytics 8.3.245  Python-3.11.1 torch-2.4.1+cpu CPU (AMD RYZEN AI MAX+ 395 w/ Radeon 8060S)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\fdm_manual_dataset\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.2, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.9, mosaic=1.0, multi_scale=False, name=yolov8m, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=fdm_manual_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\fdm_manual_training\\yolov8m, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,858,636 parameters, 25,858,620 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 454.1166.4 MB/s, size: 3377.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\fdm_manual_dataset\\labels\\train... 178 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 178/178 877.2it/s 0.2s4s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\fdm_manual_dataset\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 634.963.2 MB/s, size: 3226.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\fdm_manual_dataset\\labels\\val... 20 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 20/20 916.2it/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\fdm_manual_dataset\\labels\\val.cache\n",
      "Plotting labels to C:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\fdm_manual_training\\yolov8m\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\fdm_manual_training\\yolov8m\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100         0G      2.122      3.476      1.838          5        640: 100% ━━━━━━━━━━━━ 12/12 7.0s/it 1:242.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4s/it 2.4s\n",
      "                   all         20         22      0.829      0.222      0.209      0.106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100         0G      1.816      1.961      1.518          3        640: 100% ━━━━━━━━━━━━ 12/12 6.5s/it 1:192.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4s/it 2.4s\n",
      "                   all         20         22      0.475      0.325      0.196     0.0892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100         0G      1.582      1.411      1.362          5        640: 100% ━━━━━━━━━━━━ 12/12 6.3s/it 1:161.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
      "                   all         20         22      0.332      0.507      0.439      0.227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100         0G      1.621      1.577      1.383          5        640: 100% ━━━━━━━━━━━━ 12/12 6.4s/it 1:172.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4s/it 2.4s\n",
      "                   all         20         22      0.697        0.5      0.575      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100         0G       1.51      1.386      1.358          7        640: 100% ━━━━━━━━━━━━ 12/12 7.2s/it 1:272.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0s/it 2.0s\n",
      "                   all         20         22      0.803      0.595      0.635      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100         0G      1.489      1.332      1.306          4        640: 100% ━━━━━━━━━━━━ 12/12 6.6s/it 1:192.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
      "                   all         20         22       0.85        0.6      0.657      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100         0G      1.409      1.176      1.261          9        640: 100% ━━━━━━━━━━━━ 12/12 6.3s/it 1:162.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1s/it 2.1s\n",
      "                   all         20         22      0.777       0.54      0.672      0.365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100         0G      1.442      1.162      1.308          4        640: 100% ━━━━━━━━━━━━ 12/12 5.8s/it 1:102.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
      "                   all         20         22      0.933      0.615      0.942      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100         0G      1.322      1.085      1.225          3        640: 100% ━━━━━━━━━━━━ 12/12 6.3s/it 1:152.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4s/it 2.4s\n",
      "                   all         20         22       0.81      0.607      0.909      0.425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100         0G      1.448      1.188      1.279         38        640: 58% ━━━━━━━───── 7/12 7.8s/it 59.3s<39.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining model : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m project_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mfdm_manual_training\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m saved_path = \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtrain_and_validate\u001b[39m\u001b[34m(model, project_name)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>>> Starting training using: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET_YAML\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 2. Train\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Ultralytics automatically saves the best model during training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDATASET_YAML\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# device=dml_device,\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# amp=False,\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Overwrite if exists\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mHYPERPARAMS\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 3. Validate\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m>>> Running Validation...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\train\\Lib\\site-packages\\ultralytics\\engine\\model.py:773\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    770\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    771\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\train\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:243\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    240\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\train\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:434\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    431\u001b[39m     \u001b[38;5;28mself\u001b[39m.tloss = \u001b[38;5;28mself\u001b[39m.loss_items \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.tloss * i + \u001b[38;5;28mself\u001b[39m.loss_items) / (i + \u001b[32m1\u001b[39m)\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\train\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    512\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    513\u001b[39m         Tensor.backward,\n\u001b[32m    514\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    519\u001b[39m         inputs=inputs,\n\u001b[32m    520\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\train\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    284\u001b[39m     retain_graph = create_graph\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Florian Caspar\\Desktop\\Desly\\DefectClassification-main\\train\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    767\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    770\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "DATASET_YAML = os.path.join(os.getcwd(), 'fdm_manual_dataset', 'data.yaml')\n",
    "#MODELS = ['yolov5m6u.pt', 'yolov8m.pt', 'yolov8x.pt', 'yolov9e.pt' ]\n",
    "MODELS = ['yolov8m.pt', 'yolov8x.pt', 'yolov9e.pt' ]\n",
    "dml_device = torch_directml.device()\n",
    "print(f\"Using device: {dml_device}\")\n",
    "\n",
    "HYPERPARAMS = {\n",
    "    'epochs': 100,      # Set to 5 or 10 if you just want a quick test run!\n",
    "    'batch': 16,        # Paper used 64, but 16 is safer for typical GPUs\n",
    "    'imgsz': 640,\n",
    "    'optimizer': 'Adam', \n",
    "    'lr0': 0.0001,\n",
    "    'lrf': 0.2,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 0.0005,\n",
    "    'augment': True      \n",
    "}\n",
    "\n",
    "def train_and_validate(model, project_name):\n",
    "    model_name = model.removesuffix(\".pt\")\n",
    "    model = YOLO(model) \n",
    "\n",
    "    print(f\">>> Starting training using: {DATASET_YAML}\")\n",
    "\n",
    "    # 2. Train\n",
    "    # Ultralytics automatically saves the best model during training\n",
    "    results = model.train(\n",
    "        data=DATASET_YAML,\n",
    "        # device=dml_device,\n",
    "        # amp=False,\n",
    "        project=project_name,\n",
    "        name=model_name,\n",
    "        exist_ok=True,        # Overwrite if exists\n",
    "        verbose=True,\n",
    "        **HYPERPARAMS\n",
    "    )\n",
    "\n",
    "    # 3. Validate\n",
    "    print(\"\\n>>> Running Validation...\")\n",
    "    metrics = model.val()\n",
    "\n",
    "    # 4. Print Accuracy Scores\n",
    "    # In Object Detection, \"Accuracy\" is measured by mAP (Mean Average Precision)\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"      FINAL RESULTS\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # mAP@0.5: How accurate the boxes are (Standard Metric)\n",
    "    map50 = metrics.results_dict['metrics/mAP50(B)']\n",
    "    # mAP@0.5-0.95: Strict accuracy (Requires very tight boxes)\n",
    "    map50_95 = metrics.results_dict['metrics/mAP50-95(B)']\n",
    "    precision = metrics.results_dict['metrics/precision(B)']\n",
    "    recall = metrics.results_dict['metrics/recall(B)']\n",
    "\n",
    "    print(f\"Precision: {precision:.4f} (Few false alarms?)\")\n",
    "    print(f\"Recall:    {recall:.4f} (Found all defects?)\")\n",
    "    print(f\"mAP@0.5:   {map50:.4f} (Overall Accuracy Score)\")\n",
    "    print(f\"mAP@0.95:  {map50_95:.4f} (Strict Accuracy)\")\n",
    "    \n",
    "    # 5. Locate Saved Model\n",
    "    # It is saved automatically, but we print the exact path for you\n",
    "    best_weight_path = os.path.join(os.getcwd(), project_name, model_name , 'weights', 'best.pt')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"MODEL SAVED AT: {best_weight_path}\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    return best_weight_path\n",
    "\n",
    "for model in MODELS:\n",
    "    print(f\"Training model : {model}\")\n",
    "    project_name = f\"{'fdm_manual_training'}\"\n",
    "    saved_path = train_and_validate(model, project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de6e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
